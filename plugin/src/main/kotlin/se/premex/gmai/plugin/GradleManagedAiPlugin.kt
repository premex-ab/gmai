/*
 * This source file was generated by the Gradle 'init' task
 */
package se.premex.gmai.plugin

import org.gradle.api.Plugin
import org.gradle.api.Project
import org.slf4j.Logger
import org.slf4j.LoggerFactory
import se.premex.gmai.plugin.extensions.ManagedAiExtension
import se.premex.gmai.plugin.services.OllamaLifecycleService
import se.premex.gmai.plugin.tasks.OllamaStatusTask
import se.premex.gmai.plugin.tasks.PullModelTask
import se.premex.gmai.plugin.tasks.SetupManagedAiTask
import se.premex.gmai.plugin.tasks.StartOllamaTask
import se.premex.gmai.plugin.tasks.StopOllamaTask
import se.premex.gmai.plugin.tasks.TeardownManagedAiTask

/**
 * Gradle Managed AI Plugin
 *
 * Provides lifecycle management for Ollama LLM instances in Gradle builds.
 */
class GradleManagedAiPlugin : Plugin<Project> {

    private val logger: Logger = LoggerFactory.getLogger(GradleManagedAiPlugin::class.java)

    override fun apply(project: Project) {
        // Create the extension
        val extension = project.extensions.create("managedAi", ManagedAiExtension::class.java, project)

        // Configure after evaluation to ensure all configurations are set
        project.afterEvaluate {
            configurePlugin(project, extension)
        }
    }

    private fun configurePlugin(project: Project, extension: ManagedAiExtension) {
        logger.info("Configuring Gradle Managed AI Plugin...")

        // Register all plugin tasks
        registerTasks(project, extension)

        // Set up build services
        setupBuildServices(project, extension)

        logger.info("Gradle Managed AI Plugin configured successfully")
    }

    private fun registerTasks(project: Project, extension: ManagedAiExtension) {
        // Register core Ollama lifecycle tasks
        val startOllamaTask = project.tasks.register("startOllama", StartOllamaTask::class.java) { task ->
            task.host.set(extension.ollama.host)
            task.port.set(extension.ollama.port)
            task.autoInstall.set(extension.autoInstall)
            task.additionalArgs.set(extension.ollama.additionalArgs)
            task.allowPortChange.set(extension.ollama.allowPortChange)
            task.installationStrategy.set(extension.ollama.installationStrategy)
            extension.ollama.installPath?.let { task.installPath.set(it) }
        }

        val stopOllamaTask = project.tasks.register("stopOllama", StopOllamaTask::class.java) { task ->
            task.port.set(extension.ollama.port)
            task.gracefulShutdown.set(extension.ollama.gracefulShutdown)
            task.timeoutSeconds.set(extension.ollama.shutdownTimeout)
        }

        project.tasks.register("ollamaStatus", OllamaStatusTask::class.java) { task ->
            task.host.set(extension.ollama.host)
            task.port.set(extension.ollama.port)
            task.verbose.set(false)
        }

        // Register model management tasks
        val modelTasks = extension.models.map { model ->
            // Sanitize model name for task name - replace invalid characters with underscores
            val sanitizedTaskName = model.getName()
                .replace(Regex("[/\\\\:<>\"?*|]"), "_")
                .replaceFirstChar { it.uppercase() }

            project.tasks.register("pullModel${sanitizedTaskName}", PullModelTask::class.java) { task ->
                task.modelName.set(model.getName())
                task.modelVersion.set(model.version)
                task.host.set(extension.ollama.host)
                task.port.set(extension.ollama.port)
                task.timeoutMinutes.set(30)
                task.dependsOn(startOllamaTask)
            }
        }

        // Separate preload tasks from regular model tasks
        val preloadTasks = extension.models.filter { it.preload }.map { model ->
            val sanitizedTaskName = model.getName()
                .replace(Regex("[/\\\\:<>\"?*|]"), "_")
                .replaceFirstChar { it.uppercase() }

            project.tasks.named("pullModel${sanitizedTaskName}")
        }

        // Register high-level lifecycle tasks
        project.tasks.register("setupManagedAi", SetupManagedAiTask::class.java) { task ->
            task.host.set(extension.ollama.host)
            task.port.set(extension.ollama.port)
            task.autoInstall.set(extension.autoInstall)
            task.dependsOn(startOllamaTask)
            task.dependsOn(modelTasks)
        }

        // Register preload task for models marked with preload = true
        project.tasks.register("preloadModels") { task ->
            task.group = "ai"
            task.description = "Preload models marked with preload = true"
            task.dependsOn(startOllamaTask)
            task.dependsOn(preloadTasks)
        }

        project.tasks.register("teardownManagedAi", TeardownManagedAiTask::class.java) { task ->
            task.port.set(extension.ollama.port)
            task.gracefulShutdown.set(extension.ollama.gracefulShutdown)
            task.timeoutSeconds.set(extension.ollama.shutdownTimeout)
            task.dependsOn(stopOllamaTask)
        }

        logger.info("Plugin tasks registered successfully")
    }

    /**
     * Set up build services to manage Ollama lifecycle across builds.
     */
    private fun setupBuildServices(project: Project, extension: ManagedAiExtension) {
        // Register a build service for managing Ollama lifecycle
        val ollamaServiceProvider = project.gradle.sharedServices.registerIfAbsent(
            "ollamaLifecycleService",
            OllamaLifecycleService::class.java
        ) { spec ->
            spec.parameters.autoInstall.set(extension.autoInstall)
            spec.parameters.autoStart.set(extension.autoStart)
            spec.parameters.host.set(extension.ollama.host)
            spec.parameters.port.set(extension.ollama.port)
            spec.parameters.installationStrategy.set(extension.ollama.installationStrategy)
            spec.parameters.version.set(extension.ollama.version)
            extension.ollama.installPath?.let { spec.parameters.installPath.set(it) }
        }

        // Configure tasks to use the build service
        project.tasks.withType(StartOllamaTask::class.java).configureEach { task ->
            task.usesService(ollamaServiceProvider)
        }

        project.tasks.withType(StopOllamaTask::class.java).configureEach { task ->
            task.usesService(ollamaServiceProvider)
        }
    }
}
